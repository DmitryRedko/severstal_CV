{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torchvision.io.video import read_video\n",
    "from torchvision.models.video import r3d_18,R3D_18_Weights,s3d,S3D_Weights, mc3_18, MC3_18_Weights, r2plus1d_18, R2Plus1D_18_Weights\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision.io import read_video\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "FEATURE_EXTRACT = True\n",
    "\n",
    "USE_WEIGHTS = True\n",
    "\n",
    "MODELS_NAMES = ['MViT', 'ResNet', 's3d']\n",
    "\n",
    "TRAIN_SIZE = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train'\n",
    "validation_dir = './validation'\n",
    "\n",
    "for  i in [train_dir, validation_dir]:\n",
    "    try:\n",
    "        os.mkdir(i)\n",
    "    except FileExistsError as ex:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/videos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m videos_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m./data/videos\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m random\u001b[39m.\u001b[39mshuffle(videos_filename)\n\u001b[1;32m      3\u001b[0m videos_number \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(videos_filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/videos'"
     ]
    }
   ],
   "source": [
    "videos_filename = os.listdir('./data/videos')\n",
    "random.shuffle(videos_filename)\n",
    "videos_number = len(videos_filename)\n",
    "\n",
    "for i, vid in enumerate(videos_filename):\n",
    "    if i < round(videos_number * TRAIN_SIZE):\n",
    "        shutil.move('./data/videos/'+vid,train_dir)\n",
    "    else:\n",
    "        shutil.move('./data/videos/'+vid,validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_dataset(path):\n",
    "    df = pd.DataFrame(columns=['vid','target'])\n",
    "    vid_names = os.listdir(path)\n",
    "    for vid_name in tqdm(vid_names):\n",
    "        name, _ = vid_name.split('%')\n",
    "        _,persentage = name.split(', ')\n",
    "        df.loc[len(df)] = [vid_name, float(persentage)]\n",
    "\n",
    "    if \"train\" in path:\n",
    "        df.to_csv(f'./train_data.csv')\n",
    "    else:\n",
    "        df.to_csv(f'./val_data.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, feature_extract, use_weights):\n",
    "    \n",
    "    \"\"\"\n",
    "    Инициализация модели, которая будет использована для обучения.\n",
    "    \n",
    "    Args:\n",
    "        model_name (_str_): Название используемой модели из документации.\n",
    "        feature_extract (_bool_): _description_\n",
    "        use_weights (_bool_): Парамет, указывающий, будем ли мы использовать предобученные веса для данной модели.\n",
    "    \"\"\"\n",
    "\n",
    "    if 'r3d_18' in model_name:\n",
    "        if use_weights:\n",
    "            weights = R3D_18_Weights.KINETICS400_V1\n",
    "            model = r3d_18(weights=weights)    \n",
    "        else:\n",
    "            model = r3d_18()\n",
    "\n",
    "    if 'mc3_18' in model_name:\n",
    "        if use_weights:\n",
    "            weights = MC3_18_Weights.KINETICS400_V1\n",
    "            model = mc3_18(weights=weights)\n",
    "        else:\n",
    "            model = mc3_18()\n",
    "\n",
    "    if 'r2plus1d_18' in model_name:\n",
    "        if use_weights:\n",
    "            weights = R2Plus1D_18_Weights.KINETICS400_V1\n",
    "            model = r2plus1d_18(weights=weights)\n",
    "        else:\n",
    "            model = r2plus1d_18()\n",
    "\n",
    "    if 's3d' in model_name:\n",
    "        if use_weights:\n",
    "            weights = S3D_Weights.KINETICS400_V1\n",
    "            model = s3d(weights=weights)\n",
    "        else:\n",
    "            model = s3d()\n",
    "\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "\n",
    "    if feature_extract:\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'fc' not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VideoRegressionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, videos_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            videos_dir (string): Path to the directory containing video files.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        print(\"Creating dataset...\")\n",
    "        self.value_to_frame = create_csv_dataset(videos_dir)\n",
    "        print(\"Dataset created!\")\n",
    "        self.videos_dir = videos_dir\n",
    "        self.transformer = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.value_to_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        video_name = os.path.join(self.videos_dir, self.value_to_frame.iloc[idx, 0])\n",
    "        video, _, _ = read_video(video_name, pts_unit=\"sec\")\n",
    "\n",
    "        frames = video.permute(0, 3, 244, 244)  # Подставить нужные размеры [T, C, H, W]\n",
    "        targets = float(self.value_to_frame.iloc[idx, 1:])\n",
    "        sample = {'video': frames, 'target': targets}\n",
    "\n",
    "        if self.transformer:\n",
    "            sample = self.transformer(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(VideoRegressionDataset(\n",
    "    videos_dir='./train',\n",
    "    transform=transforms.Compose([\n",
    "        Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(VideoRegressionDataset(\n",
    "    videos_dir='./validation',\n",
    "    transform=transforms.Compose([\n",
    "        Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    '''\n",
    "    Функция для построения графиков лоса и точности.\n",
    "\n",
    "    :param history: (dict)\n",
    "        accuracy и loss на обучении и валидации\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(20, 7))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Лосс', fontsize=15)\n",
    "    plt.plot(history['loss']['train'], label='train')\n",
    "    plt.plot(history['loss']['val'], label='val')\n",
    "    plt.ylabel('лосс', fontsize=15)\n",
    "    plt.xlabel('эпоха', fontsize=15)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    model_params,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    num_epochs=15\n",
    "):\n",
    "   \n",
    "\n",
    "    history = defaultdict(lambda: defaultdict(list))\n",
    "    valid_loss_min = np.inf\n",
    "    \n",
    "    current_dir = os.getcwd()\n",
    "    model_save_dir = f'./models/{model_params[0]}'\n",
    "    try:\n",
    "        os.mkdir(model_save_dir)\n",
    "    except FileExistsError as ex:\n",
    "        pass\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model.train(True)\n",
    "        model.to(DEVICE)\n",
    "\n",
    "        # Training loop\n",
    "        print('Training')\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            # Move batch to the device\n",
    "            X_batch = batch['video'].to(DEVICE)\n",
    "            y_batch = batch['target'].to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        history['loss']['train'].append(train_loss)\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        print('Validation')\n",
    "        with torch.no_grad():\n",
    "            # Validation loop\n",
    "            for batch in tqdm(val_dataloader):\n",
    "                # Move batch to the device\n",
    "                X_batch = batch['video'].to(DEVICE)\n",
    "                y_batch = batch['target'].to(DEVICE)\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "        history['loss']['val'].append(val_loss)\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "\n",
    "        # Print results after each epoch\n",
    "        print(f'Model: {model_params[0]}. LR: {model_params[1]}. Momentum: {model_params[2]}')\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss: \\t{:.6f}\".format(train_loss))\n",
    "        print(\"  validation loss: \\t{:.6f}\".format(val_loss))\n",
    "        \n",
    "        if val_loss < valid_loss_min:\n",
    "            print(f'Detected network improvement on epoch {epoch},saving the current model')\n",
    "            valid_loss_min = val_loss\n",
    "            torch.save(model.cpu(), model_save_dir + f'\\\\{model_params[0]}_lr{model_params[1]}_mom{model_params[2]}.pth')\n",
    "        \n",
    "        plot_learning_curves(history)\n",
    "    \n",
    "    model.cpu()   \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_optimizer_and_criterion(model, learning_rate, moment):\n",
    "    params_to_update = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name + \" updating\")\n",
    "    optimizer_ft = torch.optim.SGD(\n",
    "        params_to_update,\n",
    "        lr=learning_rate,\n",
    "        momentum=moment,\n",
    "        weight_decay=0.05\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    return optimizer_ft, criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "try:\n",
    "    os.mkdir(current_directory + '\\\\models')\n",
    "except FileExistsError as ex:\n",
    "    pass\n",
    "\n",
    "for model_name in MODELS_NAMES:\n",
    "    for learning_rate in [0.0003]:\n",
    "        for moment in [0.9]:\n",
    "            model, input_size = initialize_model(model_name, FEATURE_EXTRACT, USE_WEIGHTS)  \n",
    "            model = model.to(DEVICE)\n",
    "            optimizer, criterion = prepare_optimizer_and_criterion(model, learning_rate, moment)\n",
    "            model_params = [model_name, learning_rate, moment]\n",
    "            model, history = train(\n",
    "                model,\n",
    "                model_params,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                train_dataloader,\n",
    "                validation_dataloader,\n",
    "                EPOCHS\n",
    "            )\n",
    "            time.sleep(5)\n",
    "            torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
